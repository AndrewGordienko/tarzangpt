{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d08d88e0-78e1-40d8-9db4-bd71dcbded90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x202444e4110>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import urllib.request\n",
    "import random\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "\n",
    "torch.manual_seed(1337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac40b8d7-542e-49ce-886a-ef0d490031f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "url =  'https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt'\n",
    "\n",
    "filename = 'shakespeare.txt'\n",
    "urllib.request.urlretrieve(url, filename)\n",
    "\n",
    "with open('data6.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "067eb1f4-c70d-426d-9b4f-71f31c55c97c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "vocab_size = int(len(chars))\n",
    "text_length = len(text) - 1\n",
    "block_size = 32\n",
    "batch_size = 16\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "print(vocab_size)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9808311-da52-4e20-803b-02f17488e7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_embd = 64\n",
    "n_head = 4\n",
    "n_layer = 4\n",
    "dropout = 0.0\n",
    "\n",
    "head_size = n_embd // n_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e5402dd5-711c-48b0-a034-0c6defa96ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Coding():\n",
    "  def encode(self, string):\n",
    "    string = list(string)\n",
    "    for index in range(len(string)):\n",
    "      string[index] = chars.index(string[index])\n",
    "      \n",
    "    return string\n",
    "  \n",
    "  def decode(self, integers):\n",
    "    decoded = []\n",
    "    for index in range(len(integers)):\n",
    "      decoded.append(chars[int(integers[index])])\n",
    "    return decoded\n",
    "\n",
    "coding = Coding()\n",
    "encoded_text = torch.tensor(coding.encode(text), dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23d29ab4-c531-403e-9c53-a91eb9a4ec22",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset_Creation():\n",
    "    def batch_creation(self):\n",
    "        input_data = []\n",
    "        validation_data = []\n",
    "\n",
    "        for i in range(batch_size):\n",
    "          indices = random.randint(0, text_length - block_size)\n",
    "          isolated_batch = encoded_text[indices:indices+block_size]\n",
    "          decoded_text = coding.decode(isolated_batch)\n",
    "\n",
    "          following_batch = []\n",
    "          for j in range(1, block_size+1):\n",
    "            following_batch.append(encoded_text[indices + j])\n",
    "          following_batch = torch.Tensor(following_batch)\n",
    "\n",
    "          input_data.append(isolated_batch)\n",
    "          validation_data.append(following_batch)\n",
    "\n",
    "\n",
    "        input_data = torch.stack(input_data)\n",
    "        ground_truth = torch.stack(validation_data)\n",
    "        input_data = torch.tensor(input_data, dtype=torch.long)\n",
    "        ground_truth = torch.tensor(ground_truth, dtype=torch.long)\n",
    "        \n",
    "        return input_data.to(device), ground_truth.to(device)\n",
    "\n",
    "dataset_creation = Dataset_Creation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "02c52ed7-476e-4593-8f20-e4756b125753",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer():\n",
    "    class Head(nn.Module):\n",
    "        \"\"\" one head of self-attention \"\"\"\n",
    "\n",
    "        def __init__(self, head_size):\n",
    "            super().__init__()\n",
    "            self.key = nn.Linear(n_embd, head_size, bias=False)\n",
    "            self.query = nn.Linear(n_embd, head_size, bias=False)\n",
    "            self.value = nn.Linear(n_embd, head_size, bias=False)\n",
    "            self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
    "\n",
    "            self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        def forward(self, x):\n",
    "            B,T,C = x.shape\n",
    "            k = self.key(x)   # (B,T,C)\n",
    "            q = self.query(x) # (B,T,C)\n",
    "            # compute attention scores (\"affinities\")\n",
    "            wei = q @ k.transpose(-2,-1) * C**-0.5 # (B, T, C) @ (B, C, T) -> (B, T, T)\n",
    "            wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf')) # (B, T, T)\n",
    "            wei = F.softmax(wei, dim=-1) # (B, T, T)\n",
    "            wei = self.dropout(wei)\n",
    "            # perform the weighted aggregation of the values\n",
    "            v = self.value(x) # (B,T,C)\n",
    "            out = wei @ v # (B, T, T) @ (B, T, C) -> (B, T, C)\n",
    "            return out\n",
    "\n",
    "    class MultiHeadAttention(nn.Module):\n",
    "        \"\"\" multiple heads of self-attention in parallel \"\"\"\n",
    "\n",
    "        def __init__(self, num_heads, head_size):\n",
    "            super().__init__()\n",
    "            self.heads = nn.ModuleList([Transformer.Head(head_size) for _ in range(num_heads)])\n",
    "            self.proj = nn.Linear(n_embd, n_embd)\n",
    "            self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        def forward(self, x):\n",
    "            out = torch.cat([h(x) for h in self.heads], dim=-1)\n",
    "            out = self.dropout(self.proj(out))\n",
    "            return out\n",
    "\n",
    "    class FeedFoward(nn.Module):\n",
    "        \"\"\" a simple linear layer followed by a non-linearity \"\"\"\n",
    "\n",
    "        def __init__(self, n_embd):\n",
    "            super().__init__()\n",
    "            self.net = nn.Sequential(\n",
    "                nn.Linear(n_embd, 4 * n_embd),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(4 * n_embd, n_embd),\n",
    "                nn.Dropout(dropout),\n",
    "            )\n",
    "\n",
    "        def forward(self, x):\n",
    "            return self.net(x)\n",
    "\n",
    "    class Block(nn.Module):\n",
    "        \"\"\" Transformer block: communication followed by computation \"\"\"\n",
    "\n",
    "        def __init__(self, n_embd, n_head):\n",
    "            # n_embd: embedding dimension, n_head: the number of heads we'd like\n",
    "            super().__init__()\n",
    "            head_size = n_embd // n_head\n",
    "            self.sa = Transformer.MultiHeadAttention(n_head, head_size)\n",
    "            self.ffwd = Transformer.FeedFoward(n_embd)\n",
    "            self.ln1 = nn.LayerNorm(n_embd)\n",
    "            self.ln2 = nn.LayerNorm(n_embd)\n",
    "\n",
    "        def forward(self, x):\n",
    "            x = x + self.sa(self.ln1(x))\n",
    "            x = x + self.ffwd(self.ln2(x))\n",
    "            return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a151ddf3-b1da-48e4-b679-00fcdb26eec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LanguageModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # each token directly reads off the logits for the next token from a lookup table\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n",
    "        self.position_embedding_table = nn.Embedding(block_size, n_embd)\n",
    "        self.blocks = nn.Sequential(*[Transformer().Block(n_embd, n_head=n_head) for _ in range(n_layer)])\n",
    "        self.ln_f = nn.LayerNorm(n_embd) # final layer norm\n",
    "        self.lm_head = nn.Linear(n_embd, vocab_size)\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        B, T = idx.shape\n",
    "\n",
    "        tok_emb = self.token_embedding_table(idx) # (B,T,C)\n",
    "        pos_emb = self.position_embedding_table(torch.arange(T, device=device)) # (T,C)\n",
    "        x = tok_emb + pos_emb # (B,T,C)\n",
    "        x = self.blocks(x) # (B,T,C)\n",
    "        x = self.ln_f(x) # (B,T,C)\n",
    "        logits = self.lm_head(x) # (B,T,vocab_size)\n",
    "\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "\n",
    "        return logits, loss\n",
    "\n",
    "    def generate(self, idx, max_new_tokens):        \n",
    "        # idx is (B, T) array of indices in the current context\n",
    "        for _ in range(max_new_tokens):\n",
    "            # crop idx to the last block_size tokens\n",
    "            idx_cond = idx[:, -block_size:]\n",
    "            # get the predictions\n",
    "            logits, loss = self(idx_cond)\n",
    "            # focus only on the last time step\n",
    "            logits = logits[:, -1, :] # becomes (B, C)\n",
    "            # apply softmax to get probabilities\n",
    "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
    "            # sample from the distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
    "            # append sampled index to the running sequence\n",
    "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
    "        return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4f3b2236-afa8-460b-8994-e537b5455278",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.214631 M parameters\n"
     ]
    }
   ],
   "source": [
    "model = LanguageModel()\n",
    "model = model.to(device)\n",
    "\n",
    "learning_rate = 1e-3\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "print(sum(p.numel() for p in model.parameters())/1e6, 'M parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88ecc6f-4897-4f76-98e6-a36ab13190c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                        | 0/10001 [00:00<?, ?it/s]C:\\Users\\andrew\\AppData\\Local\\Temp\\ipykernel_28360\\3338117675.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input_data = torch.tensor(input_data, dtype=torch.long)\n",
      "C:\\Users\\andrew\\AppData\\Local\\Temp\\ipykernel_28360\\3338117675.py:23: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ground_truth = torch.tensor(ground_truth, dtype=torch.long)\n",
      "  0%|                                                                                | 1/10001 [00:00<27:48,  5.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0022, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|███████▊                                                                      | 999/10001 [01:00<08:55, 16.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.9332, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|███████████████▍                                                             | 1999/10001 [02:00<07:51, 16.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.7568, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███████████████████████                                                      | 2999/10001 [03:00<06:56, 16.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.6690, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|██████████████████████████████▊                                              | 3999/10001 [04:01<05:56, 16.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.6137, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|██████████████████████████████████████▍                                      | 4999/10001 [05:01<04:52, 17.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.5749, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████████████████████████████████████████████▏                              | 5999/10001 [06:02<03:56, 16.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.5446, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|█████████████████████████████████████████████████████▉                       | 6999/10001 [07:02<02:53, 17.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.5264, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|█████████████████████████████████████████████████████████████▌               | 7999/10001 [08:03<01:58, 16.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.5066, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████████████████████████████████████████████████████████████████▎       | 8999/10001 [09:05<01:07, 14.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.4972, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|███████████████████████████████████████████████████████████████████████████▉ | 9863/10001 [09:58<00:08, 16.00it/s]"
     ]
    }
   ],
   "source": [
    "num_epochs = 10001\n",
    "total_loss = 0\n",
    "eval_iteration = 1000\n",
    "\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "    input_data, target_data = dataset_creation.batch_creation()\n",
    "    \n",
    "    logits, loss = model(input_data, target_data)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    total_loss += loss\n",
    "    if epoch % eval_iteration == 0:\n",
    "        print(total_loss/eval_iteration)\n",
    "        \n",
    "        PATH = \"C:\\\\Users\\\\andrew\\\\Desktop\\\\m_storage\"\n",
    "        torch.save(model.state_dict(), PATH)\n",
    "        model.load_state_dict(torch.load(PATH))\n",
    "        total_loss = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d71e1f-60a0-4f0e-be28-01430827920a",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
    "new_text = ''.join(coding.decode(model.generate(context, max_new_tokens=500)[0].tolist()))\n",
    "print(new_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
